\chapter{Testing}
\section{Introduzione}
Una volta che il sistema software è stato implementato, l'obiettivo è
verificare che sia corretto e allineato con quello che avremmo dovuto implementare 
in linea con i desideri sia in fase di specifica che di design e implementazione.
Sostanzialmente si tratta di verificare che il software faccia quello che deve fare e
verificare che non ci siano deformità, ovvero che non ci siano disallineamenti tra il comportamento 
che dovrebbe avere il software e quello che effettivamente ha.
\begin{tcolorbox}[title={Comportamento atteso}]
    Il comportamento atteso è quello che è stato definito in fase di specifica e design.
\end{tcolorbox}
\begin{tcolorbox}[title={Comportamento osservato}]
    Il comportamento effettivo che il sistema espone nel funzionamento
\end{tcolorbox}
Parliamo quindi di \textbf{matching} tra comportamento atteso e
comportamento osservato, eseguendo quindi almeno un test per ogni requisito raccolto,
più la combinazione di tali funzionalità.

Quando c'è una discrepanza tra comportamento atteso e comportamento osservato, 
si deve valutare se tale differenza possa essere un errore di raccolta dei requisiti,
errore di design o errore di implementazione. Tipicamente si utilizza il termine 
\textbf{bug}.
\subsection{Program testing}
Di fatto, quando parliamo di Testing, parliamo di \texttt{SUT} (\textit{System Under Test}),
ovvero sistema che stiamo testando. Per testare il sistema dobbiamo mandarlo 
in esecuzione e ciò richiede che vangano inseriti dei dati di input e che vengano 
consumati dal sistema e che calcolano quindi un output. La decisione che viene presa è 
in relazione all'allineamento tra output atteso e output osservato.
\begin{tcolorbox}
    In caso di allineamento, il test è \textbf{passato}, altrimenti è \textbf{fallito}.
\end{tcolorbox}
La terminologia però non aiuta, perché un caso di test è tanto più utile quanto più
rileva la presenza di un errore. Dicendoci quindi che su uno scenario di esecuzione 
il sistema rileva un errore.
\begin{nota}
    Il fatto che un test non rilevi un errore non significa che il sistema sia corretto,
    perché potrebbe esserci sempre scenari di esecuzione che non sono stati considerati.
    Quindi il test può solo mostrarci la presenza di errori ma non la loro assenza.
\end{nota}
\subsection{Confidenza}
Vogliamo avere una certa confidenza che il sistema non contenga bug, ovviamente per
avere una confidenza del $100\%$ dovremmo testare tutti gli scenari di esecuzione su 
tutti i possibili input, quindi si scarta la questione legata alla \textbf{completezza}
dei test.
A seconda del contesto dipendono dalle proprietà del software, legati anche 
alla criticità del software stesso, alle aspettazioni degli utenti, all'ambiente 
di marketing e di business, ecc\dots

Si tratta quindi di considerazioni ambientali più che tecniche, che ci portano a
considerare la confidenza che vogliamo avere nel sistema.

\begin{tcolorbox}[title={Testing}]
   Per testing intendiamo l'esecuzione di un sistema software su determinati input
   e la verifica che il comportamento osservato sia allineato con quello atteso.
\end{tcolorbox}
\subsection{Code review}
Un'alternativa al software testing è il \textbf{code review}, ovvero la revisione del codice
da parte di un altro sviluppatore, senza eseguire il codice, cercando di ottenere 
lo stesso risultato. Si tratta di un'attività legata all'ispezione del codice.

Ci sono diversi vantaggi nel code review, prima di tutto ciò non è limitato al codice
sorgente, ma può essere esteso anche alla documentazione, alla grafica, ai test.
Inoltre gli errori non sono mascherati, ciò significa che mandando in esecuzione il software 
con il test, al primo errore tipicamente l'esecuzione viene bloccata, nascondendo 
un possibile errore successivo.
Di fatto è possibile verificare anche altri aspetti legati alla qualità del codice,
come la leggibilità, la manutenibilità, ecc\dots
\subsection{Test driven development}
Parlando di testing, si può parlare anche di \textbf{test driven development}.
Il test driven development è una metodologia di sviluppo software che prevede
che i test vengano scritti prima del codice. Questo perché i test sono un
ottimo strumento per capire cosa deve fare il software, inoltre i test sono
un ottimo strumento per capire se il software funziona o meno.

I vantaggi del test driven development sono:
\begin{itemize}
    \item Alta copertura delle funzionalità dovuta al fatto che i test vengono
    scritti prima del codice.
    \item Si utilizzano i test come test di non regressione, ovvero per che 
    la qualità del software non regredisca nel tempo.
    \item Si semplifica la fase di debugging, in quanto si sa già dove cercare
    l'errore.
    \item Si semplifica la fase di documentazione, in quanto i test sono un ottimo
    strumento per capire cosa fa il software. Di fatto chiarisce le aspettative
    legate alla funzionalità prima ancora di implementarla.
\end{itemize}
\section{Testing}
Il testing si divide in tre fasi:
\begin{itemize}
    \item \textbf{Development testing}: è il testing che viene condotto durante
    il processo di sviluppo, ovvero durante la fase di implementazione.
    \item \textbf{Release testing}: è il testing che viene fatto prima di rilasciare
    il software in produzione.
    \item \textbf{User testing}: è il testing che viene fatto dagli utenti, ovvero
    il testing che viene fatto in produzione.
\end{itemize}

\subsection{Development testing}
Tipicamente il development testing è fatto dagli sviluppatori, quindi è un testing
svolto in parallelo con l'implementazione. L'obiettivo è quello di rilevare errori
commessi dai programmatori in fase di sviluppo, tipicamente si esegue il software 
anche con attività di debugging, quindi si esegue il software in modalità \texttt{debug}
per poter rilevare errori in particolari punti di esecuzione.

Quando parliamo di development testing abbiamo tre fasi distinte:
\begin{itemize}
    \item \textbf{Unit testing}: è il testing che viene fatto a livello di unità, 
    ovvero a livello di singola classe o di singola funzione. L'obiettivo è quello
    di verificare che la singola unità funzioni correttamente.
    \item \textbf{Component testing}: è il testing che viene fatto a livello di 
    integrazione, ovvero a livello di integrazione tra più unità. L'obiettivo è quello
    di verificare che le unità funzionino correttamente anche quando sono integrate.
    \item \textbf{System testing}: è il testing che viene fatto a livello di sistema,
    ovvero a livello di sistema software. L'obiettivo è quello di verificare che il 
    sistema software funzioni correttamente.
\end{itemize}
\subsubsection{Unit testing}
Quando abbiamo a che fare con il unit testing, abbiamo a che fare con il testing
delle singole unità, ovvero delle singole classi o delle singole funzioni.
Testare una classe significa testare tutte le funzionalità che la classe 
mette a disposizione, quindi testare tutti i metodi della classe e testare 
gli oggetti istanziati dalla classe in tutti i modi possibili.

Si tratta di un problema difficile ottenere una copertura completa, ovvero eseguire tutti 
gli scenari di esecuzione possibili. Tipicamente si cerca di ottenere una copertura
legata alla criticità del software, ovvero si cerca di ottenere una copertura
che sia proporzionale alla criticità del software.

Tipicamente lo unit testing è di questa forma:
\begin{itemize}
    \item Setup: il sistema è inizializzato in uno stato stabile.
    \item Chiamata al metodo da testare.
    \item Assert: verifica che il risultato sia allineato con quello atteso.
\end{itemize}
\begin{tcolorbox}
    È importante che i test di unità siano automatizzati, ovvero che possano essere
    eseguiti in modo automatico, senza intervento umano.
\end{tcolorbox}
Spesso non è possibile testare una singola unità in modo isolato, ma è necessario
testare una singola unità in modo integrato con altre unità o con altre componenti 
che non sono ancora state sviluppate. In questo caso si utilizzano dei \textbf{mock},
ovvero delle componenti che simulano il comportamento di altre componenti.

Ma quali scenari devono essere eseguiti? Una prima regola è quella di eseguire
gli scenari che più si adattano agli scenari realistici, ovvero agli scenari che
più si avvicinano a quelli che verranno eseguiti in produzione. 
Si dovrebbero testare anche valori anormali e valori limite, ovvero valori che
potrebbero causare problemi al sistema.
Quello che si può fare è utilizzare l'\textbf{input partitioning}, ovvero
raggruppare gli input in classi di equivalenza, ovvero raggruppare gli input
in classi che hanno lo stesso comportamento, quindi si esegue il test su un
rappresentante per ogni classe di equivalenza.

Le linea guida per il unit testing sono:
\begin{itemize}
    \item Con valori multipli si cerca di testarlo con liste di lunghezza diversa,
    cercando di scrivere test sugli elementi iniziali, sugli elementi finali e sugli
    elementi interni.
    \item Con valori booleani si cerca di testarlo con entrambi i valori.
    \item Si utilizza l'esperienza pregressa per capire quali sono i valori che
    potrebbero causare problemi.
    \item Si cerca di testare i valori che potrebbero causare problemi.
    \item ecc\dots
\end{itemize}
\subsubsection{Component testing}
Il component testing è il testing che viene fatto a livello di integrazione,
ovvero a livello di integrazione tra più unità. L'obiettivo è quello di verificare
che le unità funzionino correttamente anche quando sono integrate.
L'obiettivo è quello di verificare che le assunzioni fatte da una classe sul comportamento
dell'altra siano rispettate.
Tipicamente si verifica che il passaggio di dati avvenga in maniera corretta, 
se le due classi contengono memorie condivise, si verifica che il passaggio di
informazioni avvenga in maniera corretta, o la consistenza tra i protocolli di
comunicazione, ecc\dots

Questo avviene perché mettendo insieme due classi, è presente un contratto da 
rispettare. I tipici errori che si possono verificare sono:
\begin{itemize}
    \item Errori di interfaccia: utilizzo scorretto di come vengono fatte le chiamate
    ad esempio mediante l'utilizzo del tipo di dato sbagliato.
    \item Errori di incomprensione: quando una classe non rispetta il contratto
    che è stato definito (\textit{ad esempio liste ordinate che non sono ordinate}).
    \item Errori di tempi: quando una classe non rispetta i tempi che sono stati
    definiti (\textit{ad esempio quando una classe non rispetta i tempi di risposta}).
\end{itemize}

Le linee guida sono quelle di testare i parametri che sono agli estremi del range,
ovvero testare i parametri che sono al limite inferiore e al limite superiore.
Si cerca di testare il passaggio di puntatori nulli, si testa con chiamate che si presume mandino in 
errore dei componenti, si eseguono stress test, ecc\dots

\subsubsection{System testing}
Il system testing è il testing che viene fatto a livello di sistema, ovvero a livello
di sistema software. L'obiettivo è quello di verificare che il sistema software
funzioni correttamente. Il focus è l'interazione tra le componenti, per rilevare 
ipotesi errate sul comportamento delle componenti e che i dati vengano passati
in maniera corretta tra le componenti.

In questo caso è opportuno utilizzare gli \textbf{use case} per capire quali sono
gli scenari che devono essere eseguiti e che solo in questo momento diventano 
testabili in quanto sono stati sviluppati tutti i componenti.
Il diagramma di sequenza associato ai casi d’uso documenta i componenti e
le interazioni che stanno venendo testati, i test dovrebbero anche considerare
le eccezioni e verificare che siano correttamente gestite.

Testare tutte le possibili esecuzioni di un sistema è impossibile,
si possono però utilizzare delle policies per considerare il testing adeguato,
esempi di policies sono:
\begin{itemize}
    \item tutte le istruzioni del programma
    devono essere eseguite da almeno un test.
    \item tutte le funzioni accessibili tramite un menu dovrebbero
    essere testate così come dovrebbero esserlo tutte le combinazioni di
    funzioni accessibili dal menu.
    \item se sono forniti input dall’utente, tutte le funzioni devono essere
    testate con input corretti o errati.
\end{itemize}
\subsubsection{Release testing}
Il release testing è il testing che viene fatto a livello di sistema software
prima che il sistema venga rilasciato. L'obiettivo è quello di verificare che
il sistema sia pronto per il rilascio, ovvero che sia pronto per essere utilizzato
dagli utenti finali. 
Tipicamente tale fase viene eseguita da un team diverso da quello che ha sviluppato
il software, in modo da avere un team che non ha preconcetti sul software.
Tipicamente si utilizza il \textbf{black box testing}, ovvero si testa il software
senza conoscere la sua struttura interna, ma solo conoscendo le sue funzionalità.

\paragraph{Scenario testing}
Lo scenario è una storia che descrive un modo in cui il sistema potrebbe
essere utilizzato, un testing degli scenari quindi può includere vari requisiti
e in caso appunto scenari e user stories siano disponibili dalla fase di ingegneria
dei requisiti possono essere direttamente utilizzati come scenari di test.

\paragraph{Performance testing}
Il performance testing è il testing che viene fatto a livello di sistema software
per verificare che il sistema soddisfi i requisiti di performance.
L'obiettivo è quello di verificare che il sistema soddisfi i requisiti di performance
che sono stati definiti, ovvero che il sistema soddisfi i requisiti di tempo di
risposta, di throughput, di utilizzo di memoria, ecc\dots

Se invece parliamo di stress testing, siamo in un contesto in cui il sistema è
volutamente sovraccaricato per capire il suo comportamento quando fallisce.

\subsubsection{User testing}
L'obiettivo del user testing è quello di verificare che il sistema soddisfi le
esigenze degli utenti finali. Tipicamente viene fatto in un ambiente di test
controllato, in cui gli utenti finali utilizzano il sistema e vengono osservati
dagli sviluppatori.

Ci sono delle tipologie di user testing:
\begin{itemize}
    \item \textbf{Alpha testing}: è il testing che viene fatto con pochi utenti
    finali, in un ambiente controllato, in cui gli sviluppatori sono presenti
    e possono osservare gli utenti finali.
    \item \textbf{Beta testing}: è il testing che viene fatto con un numero maggiore
    di utenti finali, in un ambiente controllato, in cui gli sviluppatori sono
    presenti e possono osservare gli utenti finali.
    \item \textbf{Acceptance testing}: è il testing che viene fatto dagli utenti
    finali in un ambiente non controllato, in cui gli sviluppatori non sono presenti.
    In questa fase gli utenti finali utilizzano il sistema e verificano che soddisfi
    i requisiti che sono stati definiti. Decidendo quindi se accettare o meno il
    sistema.
\end{itemize}
Accettare il sistema implica l’avvenire del pagamento finale per il software, il
processo di accettazione è cosi strutturato:
Si definiscono i criteri, che se soddisfatti, comportano l’accettazione del sistema,
si definisce poi il piano di accettazione quindi risorse,tempi,budget. Si prosegue
quindi derivando i casi di test che verranno eseguiti e si eseguono questi test, i
risultati poi vengono negoziati, se ci sono test falliti si capisce come sistemare
questa condizione di incorrettezza, per finire il sistema viene o meno accettato e
di conseguenza pagato o non pagato.

\subsubsection{Metodi agili nell'acceptance testing}
Nei metodi agili il customer è parte del team di sviluppo ed è responsabile
di prendere decisioni per l’accettabilità del sistema, i test sono definiti
dal customer e integrati con altri test e vengono eseguiti automaticamente quando
sono fatti cambiamenti.
Non c’è una fase di acceptance testing separata, il problema principale è \textbf{finire}.