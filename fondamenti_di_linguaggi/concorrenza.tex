\chapter{Concorrenza}
\section{Introduzione}

Il fulcro della nostra ricerca finora è stata la semantica
delle computazioni sequenziali. Tuttavia, è importante riconoscere
che numerosi sistemi complessi operano in modalità non sequenziale.
Questa osservazione è particolarmente pertinente nell'era
dell'hardware intrinsecamente parallelo, che include:
\begin{itemize}
    \item Sistemi con architetture multi-processore.
    \item Il multi-threading, sia in contesti di processori
    singoli che multipli.
    \item Sistemi distribuiti e macchine collegate in rete.
    \item Sistemi ciber-fisici integrati.
    \item Dispositivi nell'ambito dell'Internet of Things (\textit{IoT}).
\end{itemize}
La concorrenza, in generale, può notevolmente migliorare le
prestazioni di un programma, permettendo l'esecuzione parallela
di task indipendenti su hardware multicore. Inoltre, favorisce
lo sviluppo di interfacce utente dinamiche e reattive.

La complessità dei sistemi concorrenti si manifesta anche
nell'espansione dello spazio degli stati. Con \( n \) thread,
ognuno dei quali può assumere uno di due stati, il sistema può
teoricamente raggiungere \( 2^n \) stati distinti. Oltre alla
vastità dello spazio degli stati, emergono ulteriori sfide, come:
\begin{itemize}
    \item La necessità di gestire l'accesso alle risorse condivise
    tramite meccanismi di mutua esclusione per prevenire situazioni
    di \textit{deadlock} o \textit{starvation}.
    \item La natura intrinsecamente non deterministica delle
    computazioni, che si accentua in assenza di meccanismi di
    sincronizzazione, poiché i diversi thread possono operare
    a velocità variabili.
    \item Problemi specifici della programmazione concorrente,
    tra cui le race condition, ovvero l'accesso contemporaneo
    a dati condivisi da parte di thread multipli, che può portare
    a comportamenti imprevedibili o errati.
\end{itemize}
In aggiunta a questi aspetti, i sistemi non sequenziali e
distribuiti devono affrontare sfide quali:
\begin{itemize}
    \item Fallimenti parziali (\textit{di alcuni processi, dispositivi
    in una rete o dispositivi di storage persistente}); la necessità
    di meccanismi di transazione.
    \item Comunicazione tra ambienti diversi con risorse locali
    differenti (\textit{ad esempio, diversi store locali o librerie}); la
    necessità di meccanismi di coerenza.
    \item Comunicazione tra domini amministrativi con fiducia parziale
    (\textit{o, in effetti, assenza di fiducia}); la protezione contro
    attacchi informatici.
    \item La gestione della complessità contingente.
\end{itemize}
\section{Composizione parallela}
Consideriamo il seguente linguaggio concorrente:
\begin{grammar}
    <$\texttt{Booleans} \qquad b \in \mathbb{B}$> = \texttt{true} | \texttt{false}

    <$\texttt{Integers} \qquad n \in \mathbb{N}$> = \{\dots, -1, 0, 1, \dots\}

    <$\texttt{Locations} \qquad l \in \mathbb{L}$> = \{l, l_0, l_1, \dots\}

    <$\texttt{Operations} \qquad \texttt{op}$> ::= $+$ | $\geq$

    <$\texttt{Expressions} \qquad e \in \texttt{Exp}$> ::= $n$ | $b$ | $e \, \texttt{op} \, e$ | 
    $\texttt{if} \, e \, \texttt{then} \, e \, \texttt{else} \, e$ \alt 
    $l:=e$ | $!l$ | \texttt{skip} | $e;e$ \alt 
    $\texttt{while }e \texttt{ do } e$ | \textcolor{red}{$e \, \parallel \, e$}

    <$\texttt{Types} \qquad T$> ::= \texttt{int} | \texttt{bool} | \texttt{unit} | \texttt{\textcolor{red}{proc}}

    <$\qquad \qquad T_{loc}$> ::= \texttt{intref}
\end{grammar}
Il costrutto \textcolor{red}{$e \, \parallel \, e$} è chiamato composizione parallela.
\subsection{Le nostre scelte di design}
Nel contesto della programmazione concorrente, è importante anche considerare
le seguenti caratteristiche dei thread:
\begin{itemize}
    \item I thread non restituiscono un valore.
    \item I thread sono anonimi, cioè non hanno un'identità.
    \item La terminazione di un thread non può essere direttamente osservata all'interno di un programma.
    \item I processi, in generale, sono costituiti da un pool di thread concorrenti.
    \item I thread non possono essere terminati esternamente.
\end{itemize}
Vediamo ora i cambiamenti apportati alla semantica operazionale.
\begin{prooftree}
    \AxiomC{$\Gamma \vdash e_1 : \texttt{unit}$}
    \AxiomC{$\Gamma \vdash e_2 : \texttt{unit}$}
    \LeftLabel{\small{(T-sq1)}}
    \BinaryInfC{$\Gamma \vdash e_1 ; e_2 : \texttt{unit}$}
\end{prooftree}
\begin{prooftree}
    \AxiomC{$\Gamma \vdash e_1 : \texttt{unit}$}
    \AxiomC{$\Gamma \vdash e_2 : \texttt{proc}$}
    \LeftLabel{\small{(T-sq2)}}
    \BinaryInfC{$\Gamma \vdash e_1 ; e_2 : \texttt{proc}$}
\end{prooftree}
\begin{prooftree}
    \AxiomC{$\Gamma \vdash e_1 : T_1$}
    \AxiomC{$\Gamma \vdash e_2 : T_2$}
    \LeftLabel{\small{(T-par)}}
    \RightLabel{\small{$T_1,T_2 \in \{\texttt{unit, proc}\}$}}
    \BinaryInfC{$\Gamma \vdash e_1 \, \parallel \, e_2 : \texttt{proc}$}
\end{prooftree}
\begin{prooftree}
    \AxiomC{$\langle e_1, s \rangle \rightarrow \langle e_1', s' \rangle$}
    \LeftLabel{\small{(par-L)}}
    \UnaryInfC{$\langle e_1 \, \parallel\, e_2, s \rangle \rightarrow
    \langle e_1' \, \parallel \, e_2, s' \rangle$}
\end{prooftree}
\begin{prooftree}
    \AxiomC{$\langle e_2, s \rangle \rightarrow \langle e_2', s' \rangle$}
    \LeftLabel{\small{(par-R)}}
    \UnaryInfC{$\langle e_1 \, \parallel \, e_2, s \rangle \rightarrow
    \langle e_1 \, \parallel \, e_2', s' \rangle$}
\end{prooftree}
\begin{prooftree}
    \AxiomC{$-$}
    \LeftLabel{\small{(end-L)}}
    \UnaryInfC{$\langle \texttt{skip}\, \parallel \, e_2, s \rangle \rightarrow
    \langle e_2, s \rangle$}
\end{prooftree}
\begin{prooftree}
    \AxiomC{$-$}
    \LeftLabel{\small{(end-R)}}
    \UnaryInfC{$\langle e_1 \, \parallel \, \texttt{skip}, s \rangle \rightarrow
    \langle e_1, s \rangle$}
\end{prooftree}
Dove $\Gamma \vdash e : \texttt{unit}$ è essenzialmente multithread, mentre 
$\Gamma \vdash e : \texttt{proc}$ è essenzialmente single-thread.

Come in ogni linguaggio concorrente:
\begin{itemize}
    \item I thread eseguono in modo asincrono: la semantica permette qualsiasi interleaving (intreccio) delle riduzioni dei thread.
    \item Tutti i thread possono leggere e scrivere nella memoria condivisa.
\end{itemize}
Di conseguenza, la proprietà di determinatezza (\textit{Determinacy}) non vale.
Ad esempio:
\[
\langle l := 1 \parallel l := 2, \{ l \mapsto 0 \} \rangle
\rightarrow \langle \text{skip} \parallel l := 2, \{ l \mapsto 1 \}
\rangle \rightarrow \langle \text{skip} \parallel \text{skip}, \{ l \mapsto 2 \}
\rangle \rightarrow \langle \text{skip}, \{ l \mapsto 2 \} \rangle
\]
Ma anche:
\[
\langle l := 1 \parallel l := 2, \{ l \mapsto 0 \} \rangle \rightarrow
\langle l := 1 \parallel \text{skip}, \{ l \mapsto 2 \} \rangle \rightarrow \langle
\text{skip} \parallel \text{skip}, \{ l \mapsto 1 \} \rangle \rightarrow \langle
\text{skip}, \{ l \mapsto 1 \} \rangle
\]

Nell'ambito della programmazione concorrente, è fondamentale sottolineare
che sia le operazioni di \textit{assegnamento} che di \textit{dereferenziazione}
sono considerate operazioni atomiche. Questo significa che, in
una data configurazione, lo store risultante può associare la locazione
\( l \) unicamente ai valori \( 1 \) o \( 2 \), escludendo così la possibilità
di combinazioni anomale di questi valori.

Tuttavia, quando si considera l'espressione \( (l := e) \parallel e' \),
emerge una complessità aggiuntiva. In questo contesto, i passi semantici
necessari per valutare \( e \) ed \( e' \) possono essere sovrapposti o
intrecciati. Di conseguenza, questo intreccio può generare sfide significative,
come illustrato nell'esecuzione del programma \( (l := 1 + !l) \parallel
(l := 7 + !l) \). In questo scenario, si possono verificare delle condizioni
\textit{race conditions}, portando a un output potenzialmente inaspettato
e non allineato con le intenzioni di ciascun thread.

Per esemplificare ulteriormente, consideriamo le seguenti tre configurazioni
finali possibili per l'espressione \( \langle (l := 1 + !l) \parallel (l := 7 + !l),
\{ l \mapsto 0 \} \rangle \):
\begin{enumerate}
    \item \( \langle \text{skip}, \{ l \mapsto 1 \} \rangle \)
    \item \( \langle \text{skip}, \{ l \mapsto 7 \} \rangle \)
    \item \( \langle \text{skip}, \{ l \mapsto 8 \} \rangle \)
\end{enumerate}
È importante notare che le configurazioni $(1)$ e $(2)$ sono il risultato di
interferenze durante l'esecuzione delle assegnazioni. Al contrario, solo la
configurazione $(3)$ rappresenta il risultato di una sequenza di operazioni
coerente e correttamente pianificata.

La programmazione concorrente introduce una complessità notevole a causa della
vasta gamma di possibili risultati. Infatti, l'esecuzione di programmi concorrenti
può portare a una vera e propria esplosione combinatoria degli stati possibili.
Questo fenomeno rende l'analisi e la rappresentazione di questi stati, per esempio
attraverso diagrammi dello spazio degli stati, praticabile solo per
esempi molto semplici. 

È evidente, quindi, la necessità di sviluppare metodologie più efficaci per
analizzare i programmi concorrenti.

Un aspetto cruciale da considerare è che, quasi certamente, come programmatore
non si desidera che tutti i possibili esiti siano effettivamente realizzabili.
Questo pone l'accento sulla necessità di sviluppare idiomi o costrutti di
programmazione più raffinati, che consentano di limitare e controllare meglio
le possibili evoluzioni dei programmi concorrenti. La scelta di tali strumenti
e tecniche diventa quindi un punto fondamentale per garantire che il comportamento
dei programmi concorrenti sia non solo efficace ma anche prevedibile e allineato
alle intenzioni originali del programmatore.

Per gestire efficacemente la concorrenza nei programmi, è essenziale disporre
di meccanismi per sincronizzare i thread, in modo da garantire la mutua esclusione
per l'accesso ai dati condivisi. 

Sebbene sia possibile affidarsi al supporto integrato fornito dallo scheduler,
come i mutex o le variabili di condizione, o addirittura a operazioni a basso
livello come \textit{test-and-set} (\textit{tas}) o \textit{compare-and-set}
(\textit{cas}), ciò non toglie l'importanza di comprendere e sviluppare algoritmi di
sincronizzazione intrinseci al linguaggio. Questo non solo aiuta a comprendere
meglio i principi fondamentali della concorrenza, ma offre anche una maggiore
flessibilità e controllo nella gestione delle interazioni tra thread.
\section{Aggiunta delle primitive di mutex nel linguaggio}
Aggiungiamo al linguaggio delle primitive per la gestione della concorrenza.
\begin{align*}
    \texttt{Mutex names} \quad & m \in \mathbb{M} = \{ m_1, m_2, \dots \} \\
    \texttt{Configurations} \quad &\langle e,s, \textcolor{red}{\mu} \rangle,
    \text{ dove } \mu : \mathbb{M} \rightarrow \mathbb{B} 
    \text{ è in uno stato di mutex } \\
    \texttt{Expressions} \quad & e ::= \dots \mid \textcolor{red}{e \parallel e}
    \mid \textcolor{red}{\texttt{lock } m} 
    \mid \textcolor{red}{\texttt{unlock } m}\\
\end{align*}
Dove le regole sono le seguenti:

\begin{minipage}{0.5\textwidth}
    \begin{prooftree}
        \AxiomC{$-$}
        \RightLabel{\small{(T-lock})}
        \UnaryInfC{$\Gamma \vdash \texttt{lock }m : \texttt{unit}$}
    \end{prooftree}
\end{minipage}
\begin{minipage}{0.5\textwidth}
    \begin{prooftree}
        \AxiomC{$-$}
        \RightLabel{\small{(T-unlock)}}
        \UnaryInfC{$\Gamma \vdash \texttt{unlock }m : \texttt{unit}$}
    \end{prooftree}
\end{minipage}

Mentre la semantica operazionale è la seguente:

\begin{prooftree}
    \AxiomC{$-$}
    \LeftLabel{\small{(lock)}}
    \RightLabel{\small{\texttt{if }$\neg \mu(m)$}}
    \UnaryInfC{$\langle \texttt{lock }m,s,\mu \rangle \rightarrow
    \langle \texttt{skip }, s, \mu[m \mapsto \texttt{true}] \rangle$}
\end{prooftree}

\begin{prooftree}
    \AxiomC{$-$}
    \LeftLabel{\small{(unlock)}}
    \UnaryInfC{$\langle \texttt{unlock }m,s,\mu \rangle \rightarrow
    \langle \texttt{skip }, s, \mu[m \mapsto \texttt{false}] \rangle$}
\end{prooftree}

Per evitare \textit{race conditions} possiamo riscrivere la precedente programma 
come segue:
\[
    \texttt{Prg} \defeq (\textcolor{red}{\texttt{lock m;}})
    \texttt{ l := !l + 1; }
    (\textcolor{red}{\texttt{unlock m}})
    \parallel
    (\textcolor{red}{\texttt{lock m;}})
    \texttt{ l := 7 + !l; }
    (\textcolor{red}{\texttt{unlock m}})
\]
Sia $\langle \texttt{Prg}, s_0, \mu_0\rangle$ una configurazione tale che 
$s_0 = \{l \mapsto 0\}$ e $\mu_0$ ritorni \texttt{false} per ogni
$m \in \mathbb{M}$, allora, per ogni possibile traccia di esecuzione della 
configurazione $\langle \texttt{Prg}, s_0, \mu_0\rangle$ si ha che:
\[
  \langle \texttt{Prg}, s_0, \mu_0\rangle \rightarrow^* \langle \texttt{skip},
  \{l \mapsto 8\}, \mu_0 \rangle  
\]
e nessun altra configurazione possibile.

Il risultato è che i due thread si eseguono
uno dopo l'altro in mutua esclusione. Vediamo infatti che 
due assegnamenti commutano, quindi
non è importante l'ordine in cui vengono eseguiti, ma che si finisca 
nello stesso stato finale.
\subsection{Deadlock}
Un problema che può sorgere con l'utilizzo dei mutex è il \textit{deadlock}.
Il costrutto \texttt{lock m} può bloccare l'esecuzione di un thread se il mutex 
$m$ è già in uso da un altro thread. Perciò, con l'ausilio di almeno due 
mutex $m_1$ e $m_2$, è possibile creare un programma che non termina mai:
\[
    \begin{array}{lll}
        e= & & \texttt{lock }m_1; \texttt{ lock }m_2; l_1 := !l_2;
        \texttt{ unlock }m_2; \texttt{ unlock }m_1 \\
        & \parallel & \texttt{lock }m_2; \texttt{ lock }m_1; l_2 := !l_1;
        \texttt{ unlock }m_1; \texttt{ unlock }m_2     
    \end{array}
\]
Ovviamente la proprietà di \textit{determinismo} viene meno, nonostante ciò 
la conservazione del tipo rimane valida. La tipizzazione e 
l'inferenza di tipo scarsamente cambiate, è possibile utilizzare sistemi 
di tipi molto sofisticati per imporre vincoli sulle discipline 
di \textit{locking}.

D'altra parte, la proprietà di progressione non è più garantita, a meno
che non si adotti un sistema di tipi specificamente progettato per imporre
vincoli sulle discipline di locking. Questa necessità, però, influenza
significativamente la nostra comprensione dell'equivalenza semantica,
portando a una revisione
della notazione e dell'interpretazione in tale ambito.
\section{Equivalenza semantica nel contesto della concorrenza}
Dato che i nostri sistemi di tipi non escludono più la possibilità
di processi in deadlock, è necessario rivedere le nostre equivalenze semantiche.
Prendiamo
in considerazione le equivalenze di tipo viste per i calcoli sequenziali.
\begin{tcolorbox}[title = Equivalenza delle tracce $\simeq_\Gamma$]
    $e_1 \simeq_\Gamma e_2$ se e solo se per ogni stato $\mu$ e per ogni 
    store $s$, dove $\texttt{dom}(\Gamma) \subseteq \texttt{dom}(s)$,
    abbiamo che $\Gamma \vdash e_1 : T_1$ e $\Gamma \vdash e_2 : T_2$, 
    $T_1, T_2 \in \{ \texttt{unit, proc}\}, e$:
    \begin{itemize}
        \item $\langle e_1, s, \mu \rangle \rightarrow^* 
        \langle e_1', s', \mu' \rangle \implies 
        \exists e_2' . \langle e_2, s, \mu \rangle \rightarrow^*
        \langle e_2', s', \mu' \rangle$ 
        \item $\langle e_2, s, \mu \rangle \rightarrow^*
        \langle e_2', s', \mu' \rangle \implies
        \exists e_1' . \langle e_1, s, \mu \rangle \rightarrow^*
        \langle e_1', s', \mu' \rangle$
    \end{itemize}
\end{tcolorbox}
Notiamo che ora consideriamo anche \textbf{tracce parziali}, e non solo
le configurazioni finali.
\subsubsection{Esempi}
Consideriamo i seguenti programmi:
\[
    P_1 = ((\texttt{lock m}; l:=3) \parallel (\texttt{lock m}; l:=4))
\]
\[
    Q_1 = \texttt{lock m}; (l:=3 \parallel l:=4)
\]
Se consideriamo l'equivalenza, allora $P_1 \simeq_\Gamma Q_1$, 
sia $P_1$ che $Q_1$ hanno lo stesso effetto, infatti $l$ viene modificato 
in modo non deterministico a $3$ o $4$ e il \texttt{lock} garantisce che non ci 
siano race conditions.

Considerando il contesto $C[\cdot]$, allora $C[P_1] \not \simeq_\Gamma C[Q_1]$,
infatti:
\[
    C[\cdot] \parallel (x_1 := !l; x_2 := !l; \texttt{if }!x_2 = !x_1 + 1 \texttt{ then } 
    r:=1 \texttt{ else } r:=0)
\]
Allora $\langle C[Q_1], s, \mu \rangle \rightarrow^*
\langle \texttt{skip}, s', \mu' \rangle$, con 
$s(l) = s (r) = 0$, $\mu(m) = \texttt{false}$, $s'(l) = 4, s'(r) = 1$ e
$\mu'(m) = \texttt{true}$, ma in questo caso non ci sono tracce 
$\langle C[P_1], s, \mu \rangle \rightarrow^* \langle \dots, s'', \mu'' \rangle$,
con $s'=s''$ e $\mu' = \mu''$. Questo perché $P_1$ tocca la locazione solo una 
volta.

Tuttavia, $C[\cdot]$ non è ``equo'', perché non acquisisce il mutex dopo 
l'accesso alla locazione $l$.
