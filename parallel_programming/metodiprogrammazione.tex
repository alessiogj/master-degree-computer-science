\chapter{Modelli di programmazione parallela}
\section{Introduzione}
Ci sono diversi modelli di programmazione parallela,
ognuno con i propri vantaggi e svantaggi.
\begin{itemize}
  \item \textbf{Modelli di memoria condivisa}: i processi
    condividono un unico spazio di indirizzamento.
  \item \textbf{Modelli di memoria distribuita}: i processi
    hanno spazi di indirizzamento separati.
\end{itemize}
Sebbene possa sembrare, i modelli non sono legati 
ad una specifica architettura hardware, ma possono 
essere implementati (\textit{teoricamente}) su qualsiasi
architettura.

È importante notare che non c'è un modello migliore
rispetto ad un altro, ma dipende dal problema che si
vuole risolvere e dalle caratteristiche dell'architettura
hardware a disposizione.

\section{Modelli di memoria condivisa}
Nel \textbf{modello di programmazione a memoria condivisa},
i task condividono uno spazio di indirizzi comune, che
leggono e scrivono in modo asincrono. Esistono vari
meccanismi, come i lock o i semafori, utilizzati per
controllare l'accesso alla memoria condivisa. Da un punto
di vista del programmatore, un vantaggio di questo modello
è che manca la nozione di ``proprietà'' dei dati. Ciò
implica che:
\begin{itemize}
    \item Non è necessario specificare esplicitamente
    la comunicazione dei dati tra i task.
    \item Lo sviluppo del programma può spesso essere
    semplificato.
\end{itemize}

Tuttavia, un importante svantaggio, in termini di
prestazioni, è che diventa più difficile comprendere
e gestire la \textbf{località dei dati}. Mantenere i
dati locali al processore che ci lavora su conserva gli
accessi alla memoria, i refresh della cache e il traffico
sul bus che si verifica quando più processori utilizzano
gli stessi dati. Sfortunatamente, controllare la località
dei dati è difficile da capire ed è al di fuori del
controllo dell'utente medio.

\section{Modello a Thread}
Nel modello di programmazione parallela basato sui
\textbf{thread}, un singolo processo può avere più
percorsi di esecuzione concorrenti. Questa modalità
permette di eseguire diverse parti di un programma
in parallelo, aumentando l'efficienza e riducendo
il tempo di esecuzione.

\subsection{Analogia e Funzionamento}
Un'analogia semplice per descrivere i thread è il concetto
di un singolo programma che include un numero di subroutine:
\begin{itemize}
    \item Il programma principale \texttt{a.out} viene
    schedulato per l'esecuzione dal sistema operativo
    nativo. \texttt{a.out} carica e acquisisce tutte le
    risorse di sistema e utente necessarie per l'esecuzione.
    \item \texttt{a.out} esegue del lavoro seriale e poi
    crea un numero di task (\textit{thread}) che possono
    essere
    schedulati ed eseguiti contemporaneamente dal sistema
    operativo.
    \item Ogni thread ha dati locali, ma condivide anche
    tutte le risorse di \texttt{a.out}, risparmiando così
    l'overhead associato alla replicazione delle risorse
    del programma per ogni thread. Ogni thread beneficia
    anche di una visione globale della memoria perché
    condivide lo spazio di memoria di \texttt{a.out}.
    \item Il lavoro di un thread può essere descritto
    come una subroutine all'interno del programma
    principale. Qualsiasi thread può eseguire qualsiasi
    subroutine allo stesso tempo degli altri thread.
    \item I thread comunicano tra loro tramite la memoria
    globale (\textit{aggiornando le posizioni degli indirizzi}).
    Ciò richiede costrutti di sincronizzazione per
    assicurare che più di un thread non stia aggiornando
    lo stesso indirizzo globale contemporaneamente.
    \item I thread possono essere creati e terminati,
    ma \texttt{a.out} rimane presente per fornire le
    risorse condivise necessarie fino al completamento
    dell'applicazione.
\end{itemize}

\subsection{Implementazioni e Standardizzazione}
I thread sono comunemente associati con architetture
di memoria condivisa e sistemi operativi. Dal punto di
vista della programmazione, le implementazioni dei thread
comprendono comunemente:
\begin{itemize}
    \item Una libreria di subroutine che vengono chiamate
    all'interno del codice sorgente parallelo.
    \item Un insieme di direttive del compilatore
    integrate nel codice sorgente, sia seriale che
    parallelo.
\end{itemize}
In entrambi i casi, il programmatore è responsabile della
determinazione di tutto il parallelismo.

Le implementazioni basate su thread non sono una novità
nel campo dell'informatica. Storicamente, i fornitori
di hardware hanno implementato le loro versioni
proprietarie di thread, le quali differivano
sostanzialmente l'una dall'altra, rendendo difficile
per i programmatori sviluppare applicazioni threaded
portabili. Sforzi di standardizzazione non correlati
hanno risultato in due implementazioni molto diverse di
thread:
\begin{itemize}
    \item \texttt{POSIX Threads}
    \item \texttt{OpenMP}
\end{itemize}

\section{Modello Message Passing}
Il modello di passaggio di messaggi dimostra le seguenti
caratteristiche principali:

\begin{itemize}
    \item Un insieme di task che utilizzano la propria
    memoria locale durante il calcolo. Più task possono
    risiedere sulla stessa macchina fisica così come su
    un numero arbitrario di macchine.
    \item I task scambiano dati attraverso la
    comunicazione inviando e ricevendo messaggi.
    \item Il trasferimento di dati richiede di solito
    operazioni cooperative da eseguire da ciascun processo.
    Ad esempio, un'operazione di invio deve avere
    un'operazione di ricezione corrispondente.
\end{itemize}

Dal punto di vista della programmazione, le implementazioni
del passaggio di messaggi comprendono comunemente una
libreria di subroutine che sono incorporate nel codice
sorgente.

Il programmatore è responsabile della determinazione di
tutto il parallelismo.
\section{Modello di Parallelismo dei Dati}
Il modello di parallelismo dei dati dimostra le seguenti
caratteristiche principali:

\begin{itemize}
    \item La maggior parte del lavoro parallelo si
    concentra sull'esecuzione di operazioni su un
    insieme di dati. L'insieme di dati è tipicamente
    organizzato in una struttura comune, come un array
    o un cubo.
    \item Un insieme di task lavora collettivamente sulla
    stessa struttura di dati, tuttavia, ogni task lavora
    su una partizione diversa della stessa struttura di
    dati.
    \item I task eseguono la stessa operazione sulla loro
    partizione di lavoro, per esempio, ``aggiungere 4 a
    ogni elemento dell'array''.
\end{itemize}

Sulle architetture a memoria condivisa, tutti i task
possono avere accesso alla struttura di dati tramite
la memoria globale. Sulle architetture a memoria
distribuita, la struttura di dati è suddivisa e risiede
come "chunk" nella memoria locale di ogni task.

\subsection{Programmazione con il Modello di Parallelismo
dei Dati}
La programmazione con il modello di parallelismo dei dati
si realizza solitamente scrivendo un programma con
costrutti di parallelismo dei dati. I costrutti possono
essere chiamate a una libreria di subroutine di
parallelismo dei dati o direttive del compilatore
riconosciute da un compilatore di parallelismo dei dati.

\subsubsection{Direttive del Compilatore}
Permettono al programmatore di specificare la
distribuzione e l'allineamento dei dati. Le
implementazioni Fortran sono disponibili per le
piattaforme parallele più comuni.

\subsubsection{Implementazioni a Memoria Distribuita}
Le implementazioni di questo modello su memoria
distribuita di solito hanno il compilatore che converte
il programma in codice standard con chiamate a una
libreria di passaggio di messaggi (\textit{solitamente \texttt{MPI}})
per distribuire i dati a tutti i processi. Tutto il
passaggio di messaggi è invisibile al programmatore.

\section{Altri modelli di programmazione parallela}
Oltre ai modelli di programmazione parallela
precedentemente menzionati, esistono certamente
altri modelli, che continueranno a evolversi insieme
al mondo sempre in cambiamento dell'hardware e del
software per computer. Qui ne vengono menzionati
solamente tre tra i più comuni: ibrido, \texttt{SPMD}
(\textit{Single Program Multiple Data}) e \texttt{MPMD}
(\textit{Multiple Program Multiple Data}).

\subsection{Modello Ibrido}
In questo modello, vengono combinati due o più modelli
di programmazione parallela. Esempi comuni di modello
ibrido includono:
\begin{itemize}
    \item La combinazione del modello di passaggio di
    messaggi (\texttt{MPI}) con il modello dei thread
    (\textit{\texttt{POSIX} threads}) o il modello di
    memoria condivisa (\texttt{OpenMP}). Questo modello
    ibrido si presta bene all'ambiente hardware sempre
    più comune di macchine SMP in rete.
    \item La combinazione del parallelismo dei dati con
    il passaggio di messaggi. Come menzionato nella
    sezione relativa al modello di parallelismo dei dati,
    le implementazioni di parallelismo dei dati su
    architetture a memoria distribuita utilizzano
    effettivamente il passaggio di messaggi per
    trasmettere dati tra i task, in modo trasparente
    per il programmatore.
\end{itemize}

\subsection{Single Program Multiple Data (\texttt{SPMD})}
\begin{itemize}
    \item \texttt{SPMD} è un modello di programmazione
    ``di alto livello'' che può essere costruito su
    qualsiasi combinazione dei modelli di programmazione
    parallela precedentemente menzionati.
    \item Un singolo programma viene eseguito
    simultaneamente da tutti i task.
    \item In un dato momento, i task possono eseguire
    le stesse o diverse istruzioni all'interno dello
    stesso programma.
    \item A differenza di \texttt{SIMD}, in \texttt{SPMD},
    processori autonomi eseguono simultaneamente lo stesso
    programma in punti indipendenti, anziché in modo
    sincronizzato come impone \texttt{SIMD} su dati
    diversi.
    \item I programmi \texttt{SPMD} di solito hanno la
    logica necessaria programmata per permettere ai
    diversi task di eseguire condizionalmente solo
    quelle parti del programma che sono progettati per
    eseguire.
\end{itemize}

\subsection{Multiple Program Multiple Data (\texttt{MPMD})}
\begin{itemize}
    \item Come \texttt{SPMD}, anche \texttt{MPMD} è un
    modello di programmazione ``di alto livello'' che può
    essere basato su qualsiasi combinazione dei modelli
    di programmazione parallela menzionati.
    \item Le applicazioni \texttt{MPMD} tipicamente hanno
    più file oggetto eseguibili (\textit{programmi}). Mentre
    l'applicazione viene eseguita in parallelo, ciascun
    task può eseguire lo stesso programma o programmi
    diversi rispetto agli altri task.
\end{itemize}
