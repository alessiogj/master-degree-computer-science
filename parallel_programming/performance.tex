\chapter{Misurazione delle Performance}

Ci sono due punti di vista nella misurazione delle
performance:
\begin{itemize}
  \item \textbf{Utente}: tempo di risposta, throughput,
  tempo di completamento.
  \item \textbf{Sviluppatore}: tempo di esecuzione, tempo
  di CPU, tempo di I/O, tempo di comunicazione.
\end{itemize}

Il \textbf{tempo di risposta} è il tempo che intercorre
tra la partenza del codice e la fine dell'esecuzione. Il
\textbf{throughput} è la quantità di lavoro fatto dal
sistema in un determinato periodo di tempo (\textit{si considera
l'ammontare di lavoro}). La \textbf{latenza} di
un'istruzione, nel caso della pipeline, è il tempo che
intercorre tra l'arrivo di un'istruzione e la sua completa
esecuzione.

\section{Benchmark}

Quando misuriamo le performance di un sistema, dobbiamo
capire come misurarle in termini di architettura. Un
\textbf{benchmark} è un programma che misura le
performance di un sistema. I benchmark possono essere:
\begin{itemize}
  \item \textbf{Sintetici}: programmi che eseguono
  operazioni tipiche di un'applicazione e stimolano
  quindi certi comportamenti dell'architettura.
  \item \textbf{Kernel}: frammenti di codice che
  rappresentano operazioni fondamentali e critiche per
  la performance di sistemi computazionali.
  \item \textbf{Toy}: programmi molto semplici che
  eseguono operazioni elementari.
  \item \textbf{Suits}: insiemi di benchmark che
  permettono una valutazione complessiva delle performance
  di un sistema.
\end{itemize}

Sul piatto della bilancia ci sono le \textbf{performance}
e il \textbf{costo}. Generalmente, si esegue un benchmark
più volte e si calcola la media dei risultati ottenuti
per ottenere una misura affidabile delle performance.

\section{Principi Quantitativi}

La prima cosa da fare per migliorare le performance
di un sistema è capire come parallelizzare un codice
sequenziale. Innanzitutto, si inizia analizzando e
ottimizzando la parte di codice che viene eseguita più
frequentemente, noto come \textit{hot spot} del codice.
\subsection{Legge di Amdahl}

La legge di Amdahl ci dice che la velocità di un sistemap
arallelo è limitata dalla frazione sequenziale del codice.
Tale legge ci aiuta a comprendere quanto possiamo
migliorare le performance di un sistema. Non ci
interessano le righe di codice, ma le funzioni che
vengono eseguite più frequentemente. Per identificarle,
generalmente vengono utilizzati dei \textit{profiler}.

La formula della legge di Amdahl per il calcolo dello
speedup \(S(n)\) è:
\[
  S(n) = \frac{\texttt{ExecutionTime}_{\texttt{old}}}
  {\texttt{ExecutionTime}_{\texttt{new}}}
  = \frac{1}{(1-\texttt{Fraction}_{\texttt{improved}})
  + \frac{\texttt{Fraction}_{\texttt{improved}}}
  {\texttt{Speedup}_{\texttt{improved}}}}
\]

Di natura, la legge di Amdahl ci indica che non possiamo
migliorare le performance di un sistema in maniera
illimitata. Dovremo quindi cercare di parallelizzare
solamente le parti che presentano un potenziale
parallelismo.

Ne segue che lo speedup globale può essere calcolato come:
\[
  S(n) = \frac{1}{(1-\texttt{Fraction}_{\texttt{improved}})
  + \frac{\texttt{Fraction}_{\texttt{improved}}}{n}} \leq 
    \frac{1}{(1-\texttt{Fraction}_{\texttt{improved}})}
\]
Ovvero, lo speedup è limitato dalla frazione sequenziale
del codice. Con il \(50\%\) di codice parallelo,
lo speedup massimo è \(2\).

\subsubsection{Esempio}

Supponiamo che una parte di un programma possa essere
migliorata di 10 volte e che questa parte sia eseguita
nel \(40\%\) del tempo totale. Lo speedup massimo sarà:
\[
  S(n) = \frac{1}{(1-0.4) + \frac{0.4}{10}} =
  \frac{1}{0.6 + 0.04} = \frac{1}{0.64} = 1.56
\]

\section{Il tempo è un'unità di misura}
Il tempo di esecuzione di un programma è una misura
delle performance. 
Nel tempo di \texttt{CPU} non si considera il tempo di
I/O, mentre nel tempo di risposta si considera anche il 
tempo di latenza di accesso al disco.

Un altro parametro da considerare è il numero di istruzioni
del programma e il numero di cicli di clock per queste istruzioni,
ovvero il \texttt{CPI}.
\[
  \texttt{CPI} = \frac{\texttt{ClockCycles}}{\texttt{Instructions}}  
\]
\[
  \texttt{CPU time} = \texttt{Instructions} \cdot \texttt{CPI} \cdot \texttt{clock cycle time}
  = \frac{\texttt{Instructions} \cdot \texttt{CPI}}{\texttt{clock frequency}}
\]
\[
  \texttt{CPU time} = \texttt{CI} \cdot \texttt{CPI} \cdot \texttt{T}_\texttt{clock}
\]
Il tempo di \texttt{CPU} dipende da tre fattori:
\begin{itemize}
  \item \textbf{Cicli di clock (\textit{o frequenza})}: dipende 
  dall'architettura del processore.
  \item \texttt{CPI}: dipende dall'organizzazione dell'architettura e 
  dall'insieme di istruzioni.
  \item \textbf{Numero di istruzioni}: dipende dall'insieme di istruzioni
  e dalla tecnologia di compilazione.
\end{itemize}
\section{\texttt{MIPS} o \texttt{GIPS}}
Il \texttt{MIPS} (\textit{Million Instructions Per Second}) è una
misura delle performance di un processore, legata al \textit{throughput}.
Tante volte quando si usano queste unità di misura, in alcuni casi, 
sono controituitive, non viene fatta una distinzione tra istruzioni complesse 
e istruzioni semplici.

Nasce quindi il \texttt{GFLOPS} (\textit{Giga Floating Point Operations Per Second}),
che misura il numero di operazioni in virgola mobile eseguite in un secondo.

\[
  \texttt{GFLOPS} = \frac{\texttt{Numero di operazioni floating point nel programma}}{10^9}
\]
Il problema di queste unità di misura è che non tengono conto
della complessità delle operazioni.
Usiamo quindi il \texttt{GFLOPS} normalizzato, che tiene conto
della complessità delle operazioni.