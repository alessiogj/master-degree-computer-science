\chapter{Introduzione}
\section{Cos'è la programmazione parallela?}
Tradizionalmente, il software è stato scritto per delle 
computazioni sequenziali. Questo significa che le istruzioni
sono eseguite una dopo l'altra, in un ordine ben definito.
Le applicazioni, quindi, venivano eseguite su un singolo
computer con una singola unità centrale di elaborazione (\texttt{CPU}).

Nel senso più elementare, il calcolo parallelo consiste nell'utilizzo
simultaneo di diverse risorse di elaborazione
per affrontare un problema computazionale. Questo processo prevede:
\begin{itemize}
    \item \textbf{L'impiego di più unità di elaborazione (\texttt{CPU})}: per distribuire
    l'esecuzione del compito
    su diversi processori, accelerando così il tempo di elaborazione.
    \item \textbf{La divisione del problema in parti
    discrete}: ogni problema viene scomposto in segmenti più piccoli che
    possono essere
    processati in parallelo, ovvero contemporaneamente, su diverse \texttt{CPU}.
    \item \textbf{La suddivisione di ogni parte in una serie di istruzioni}:
    ciascuna frazione del problema viene poi ulteriormente frammentata in istruzioni
    specifiche,
    che definiscono esattamente cosa deve essere fatto.
    \item \textbf{L'esecuzione simultanea delle istruzioni su differenti \texttt{CPU}}: le
    istruzioni appartenenti a segmenti differenti del problema vengono
    eseguite nello stesso momento ma su processori distinti,
    permettendo così una soluzione più rapida del problema complessivo.
\end{itemize}
Questo approccio sfrutta al massimo le capacità delle moderne architetture
informatiche, permettendo di risolvere problemi complessi in tempi
significativamente ridotti rispetto al calcolo sequenziale,
dove le istruzioni vengono eseguite una dopo l'altra su un'unica \texttt{CPU}.

\section{Perché la programmazione parallela?}

La \textbf{computazione parallela} sfrutta l'uso simultaneo di molteplici
risorse di calcolo per risolvere problemi computazionali. Questo approccio
offre diversi vantaggi significativi, tra cui:
\begin{itemize}
    \item \textbf{Risparmio di Tempo e Denaro:} La distribuzione di un compito su più CPU può ridurre il tempo di completamento e i costi.
    \item \textbf{Risolvere Problemi Più Grandi:} Alcuni problemi sono troppo grandi o complessi per essere gestiti da un singolo computer.
    \item \textbf{Concorrenza:} Diverse risorse di calcolo permettono di eseguire molteplici operazioni in parallelo.
    \item \textbf{Uso di Risorse Non Locali:} L'accesso a risorse di calcolo su reti geografiche estese o su Internet consente di superare le limitazioni delle risorse locali.
\end{itemize}

\subsection{Limiti del Calcolo Seriale}
Il calcolo seriale presenta limiti fisici e pratici, tra cui:
\begin{itemize}
    \item \textbf{Velocità di Trasmissione:} I limiti alla velocità di trasmissione dei dati impongono un tetto alle prestazioni dei computer seriali.
    \item \textbf{Limiti alla Miniaturizzazione:} Esiste un limite fisico a quanto possano essere piccoli i componenti di un processore.
    \item \textbf{Limitazioni Economiche:} Aumentare la velocità di un singolo processore è progressivamente più costoso.
    \item \textbf{Consumo Energetico:} I core paralleli tendono a consumare meno energia rispetto a un equivalente core sequenziale.
\end{itemize}

\subsection{Tendenze e Futuro del Calcolo Parallelo}
L'evoluzione delle architetture informatiche evidenzia un crescente affidamento sul parallelismo hardware, attraverso:
\begin{itemize}
    \item Unità di esecuzione multiple
    \item Istruzioni in pipeline
    \item Processori Multi-core e Many-core
\end{itemize}
Queste tendenze confermano che il futuro del calcolo è orientato verso
il parallelismo.
\section{Concetti di base e terminologia}
\subsection{Tipologie di Computer e Sistemi}
Ci sono diversi tipi di computer e sistemi che possono
essere utilizzati per eseguire applicazioni parallele, tra cui:
\subsubsection{Computer Desktop}
I computer desktop sono sistemi personali comunemente usati in ambienti domestici e uffici per svariate applicazioni, da quelle produttive a quelle di intrattenimento.

\subsubsection{Computer Embedded}
I computer embedded sono sistemi specializzati progettati per eseguire compiti specifici all'interno di dispositivi più grandi, come automobili, elettrodomestici e sistemi di controllo industriale.

\subsubsection{Internet of Things (\texttt{IoT})}
\begin{itemize}
    \item \textbf{Computer Embedded Collegati a Internet:} Dispositivi embedded che sono connessi a Internet per fornire funzionalità avanzate, come il monitoraggio remoto e il controllo.
    \item \textbf{Sistemi Smart:} L'\texttt{IoT} abilita la creazione di sistemi intelligenti che combinano sensori, attuatori e connettività per interagire con il mondo fisico in modi avanzati.
\end{itemize}

\subsubsection{Dispositivi Mobili Personali (\texttt{PMDs})}
Include smartphone, tablet e altri dispositivi portatili che forniscono una vasta gamma di funzionalità, dalla comunicazione all'accesso a Internet e applicazioni specializzate.

\subsubsection{Server}
Potenti computer progettati per gestire richieste di dati e servizi da parte di altri computer e dispositivi all'interno di reti aziendali e su Internet.

\subsubsection{Cluster e Computer su Scala di Magazzino}
\begin{itemize}
    \item \textbf{Cluster:} Insiemi di computer connessi che lavorano insieme come un'unica entità per fornire elevate prestazioni di calcolo e disponibilità.
    \item \textbf{Computer su Scala di Magazzino:} Grandi infrastrutture informatiche che supportano applicazioni di cloud computing e servizi Internet su larga scala.
    \item \textbf{Supercomputer vs. Cluster:} Mentre i supercomputer sono sistemi altamente specializzati per compiti di calcolo intensivo, i cluster rappresentano un approccio più scalabile e flessibile al calcolo ad alte prestazioni.
\end{itemize}

\subsection{La Struttura von Neumann}

La struttura von Neumann, che prende il nome dal matematico
ungherese John von Neumann, rappresenta il modello di base seguito
dalla maggior parte dei computer moderni. Questo modello fu descritto
per la prima volta nei documenti del $1945$, evidenziando i requisiti
generali per un computer elettronico. A differenza dei primi computer,
programmati attraverso un cablaggio fisso, la struttura von Neumann
introduce un design flessibile e potente.

La struttura è composta da quattro componenti principali:

\begin{enumerate}
    \item \textbf{Memoria:} Serve per memorizzare le istruzioni del programma
    e i dati. Le istruzioni sono codificate per dire al computer cosa fare,
    mentre i dati sono le informazioni elaborate dal programma.
    \item \textbf{Unità di Controllo:} Preleva le istruzioni e i dati dalla
    memoria, decodifica le istruzioni e coordina le operazioni per eseguire
    il compito programmato.
    \item \textbf{Unità Logica Aritmetica (\texttt{ALU}):} Esegue le operazioni
    aritmetiche
    e logiche di base.
    \item \textbf{Input/Output:} Funge da interfaccia tra il computer e l'utente,
    permettendo l'ingresso e l'uscita dei dati.
\end{enumerate}

La memoria a accesso casuale (\texttt{RAM}), che permette sia la lettura che la scrittura,
è fondamentale in questa architettura per la memorizzazione sia delle istruzioni
che dei dati necessari per l'esecuzione del programma.

\subsection{Tassonomia di Flynn}
La tassonomia di Flynn è un sistema di classificazione per le architetture dei computer multi-processore, basato sul numero di flussi di istruzioni e dati che possono gestire in parallelo. Utilizza due dimensioni: Istruzione e Dati, ognuna delle quali può essere Singola o Multipla. Questo porta a quattro possibili classificazioni nella tassonomia di Flynn, che forniscono un quadro di riferimento per comprendere le diverse modalità di calcolo parallelo.

\section{Tassonomia di Flynn}
La tassonomia di Flynn classifica le architetture di calcolo parallelo
basandosi su due dimensioni: il numero di flussi di istruzioni
e il numero di flussi di dati che il sistema può gestire.
Ogni dimensione può essere Singola o Multipla,
portando a quattro categorie principali:

\begin{itemize}
    \item \textbf{\texttt{SISD} (Single Instruction, Single Data)}: un processore esegue un flusso di istruzioni su un flusso di dati.
    \item \textbf{\texttt{SIMD} (Single Instruction, Multiple Data)}: un'istruzione controlla simultaneamente più operazioni su diversi flussi di dati.
    \item \textbf{\texttt{MISD} (Multiple Instruction, Single Data)}: più istruzioni operano su un singolo flusso di dati, utilizzato raramente.
    \item \textbf{\texttt{MIMD} (Multiple Instruction, Multiple Data)}: più processori eseguono istruzioni diverse su flussi di dati diversi, comunemente usato per applicazioni parallele general-purpose.
\end{itemize}

In un sistema di elaborazione, l'esecuzione di programmi e la gestione dei dati
sono basate su cinque componenti chiave, che insieme formano il cuore funzionale
di qualsiasi computer moderno:

\begin{itemize}
    \item \texttt{IS} (Instruction Stream): il flusso di istruzioni, ovvero le operazioni
    che il sistema deve eseguire, organizzate in sequenza.
    \item \texttt{DS} (Data Stream): il flusso di dati comprende gli operandi sui quali
    operano le istruzioni e i risultati di tali operazioni.
    \item \texttt{CU} (Control Unit): l'unità di controllo, che si occupa di prelevare le
    istruzioni dalla memoria, decodificarle e coordinare l'esecuzione.
    \item \texttt{PU} (Processing Unit): l'unità di elaborazione, costituita dall'\texttt{ALU}
    (\textit{Arithmetic Logic Unit}) e dai registri, esegue le istruzioni operative.
    \item \texttt{MM} (Main Memory): la memoria principale, dove vengono allocati i
    dati e le istruzioni necessari per l'esecuzione di un programma.
\end{itemize}

Questi componenti interagiscono tra loro per processare efficacemente
i dati e le istruzioni, permettendo al sistema di eseguire una vasta
gamma di compiti.
\subsection{Single instruction, single data - \texttt{SISD}}
Nella struttura di Von Neumann, l'Unità di Controllo (\texttt{CU}) ha il
compito di prelevare le istruzioni dalla Memoria Principale (\texttt{MM}), mentre
l'Unità di Elaborazione (\texttt{PU}) esegue tali istruzioni interagendo con la \texttt{MM}
per modificare i dati. Questo schema rappresenta il funzionamento base della
struttura di Von Neumann, in cui un singolo programma è in esecuzione e si basa
su un unico flusso di dati.

La \texttt{CU} coordina il processo di esecuzione leggendo sequenzialmente
le istruzioni dal programma memorizzato nella \texttt{MM}, decodificandole e trasferendole
alla \texttt{PU} per la loro esecuzione. La \texttt{PU}, a sua volta, esegue le operazioni aritmetiche
e logiche specificate dalle istruzioni, utilizzando i dati memorizzati nella \texttt{MM}.
Questo processo iterativo tra \texttt{PU}, \texttt{PU} e \texttt{MM} permette l'elaborazione dei programmi
secondo il modello di flusso di dati e di controllo definito dalla struttura di
Von Neumann.

Un computer seriale (\textit{non parallelo}) si caratterizza per il singolo flusso di
istruzioni e dati. Durante ogni ciclo di clock, la \texttt{CPU} elabora:

\begin{itemize}
    \item \textbf{Singola istruzione:} Viene processato solo un flusso di istruzioni.
    \item \textbf{Singolo dato:} Viene utilizzato come input un solo flusso di dati.
\end{itemize}

Questo comporta un'esecuzione deterministica, in cui il risultato del calcolo
è direttamente determinato dall'algoritmo e dai dati in ingresso. Esempi comuni
di computer seriali includono mainframe di vecchia generazione, minicomputer
e workstation.

\subsection{Single instruction, multiple data - \texttt{SIMD}}
Un tipo di computer parallelo conosciuto come \texttt{SIMD} (\textit{Single Instruction, 
Multiple Data}) possiede le seguenti caratteristiche:

\begin{itemize}
    \item \textbf{Singola istruzione:} Tutte le unità di elaborazione
    eseguono la stessa istruzione in qualsiasi ciclo di clock.
    \item \textbf{Dati multipli:} Ogni unità di elaborazione può operare
    su un elemento di dati diverso.
\end{itemize}

Questa architettura è particolarmente adatta per problemi specializzati
caratterizzati da un alto grado di regolarità, come l'elaborazione di grafica
e immagini. L'esecuzione è sincrona (\textit{lockstep}) e deterministica.

La maggior parte dei computer moderni, in particolare quelli dotati di unità
di elaborazione grafiche (\texttt{GPU}), impiega istruzioni \texttt{SIMD} e
unità di esecuzione.

\subsection{Multiple instruction, single data - \texttt{MISD}}
Un computer parallelo \texttt{MISD} (\textit{Multiple Instruction, Single Data})
è caratterizzato da:

\begin{itemize}
    \item Un singolo flusso di dati che viene elaborato da più unità di elaborazione.
    \item Ogni unità di elaborazione processa i dati in modo indipendente
    attraverso propri flussi di istruzioni.
\end{itemize}

Questa architettura è raramente utilizzata, poiché è difficile da implementare
e non offre vantaggi significativi rispetto ad altre architetture parallele.

\subsection{Multiple instruction, multiple data - \texttt{MIMD}}
Il computer parallelo di tipo \texttt{MIMD} (\textit{Multiple Instruction, Multiple Data})
è attualmente la forma più comune di calcolo parallelo e la maggior parte
dei computer moderni rientra in questa categoria. Le caratteristiche distintive
sono:

\begin{itemize}
    \item \textbf{Istruzioni Multiple:} ogni processore può eseguire un flusso
    di istruzioni diverso.
    \item \textbf{Dati Multipli:} ogni processore può lavorare con un
    proprio flusso di dati.
    \item L'esecuzione può essere sincrona o asincrona, deterministica o
    non deterministica.
\end{itemize}

Esempi di questa architettura includono la maggior parte dei supercomputer attuali,
i cluster di computer paralleli connessi in rete e le ``griglie'' di calcolo,
i computer \texttt{SMP} (\textit{Symmetric Multi-Processing}) con più processori
e i \texttt{PC} multi-core.
\begin{nota}
    Molte architetture \texttt{MIMD} includono anche sottocomponenti di esecuzione
    \texttt{SIMD}.
\end{nota}

\section{Concetti di Esecuzione}

\subsection{Task}
Un task è un'unità di lavoro computazionale che corrisponde a un programma o a una sequenza di istruzioni eseguite da un processore. Ogni task è progettato per completare una parte specifica del lavoro generale richiesto dal programma completo.

\subsection{Esecuzione Seriale}
L'esecuzione seriale implica il processamento di istruzioni una alla volta, in una sequenza ordinata. Questo metodo di esecuzione è tipico dei computer con un singolo processore e si basa su un modello computazionale che non prevede l'esecuzione contemporanea di più istruzioni o task.

\paragraph{Implicazioni dell'Esecuzione Seriale}
Questo tipo di esecuzione è caratterizzato da un flusso di lavoro prevedibile e da una facile individuazione e risoluzione degli errori. È particolarmente efficace in applicazioni dove le operazioni devono essere svolte in una sequenza specifica e dove le istruzioni successive dipendono dai risultati di quelle precedenti.

\subsection{Esecuzione Parallela}
Contrariamente all'esecuzione seriale, l'esecuzione parallela permette a più task di essere eseguiti simultaneamente. Questo approccio sfrutta l'architettura dei computer multi-processore per ridurre il tempo totale di elaborazione.

\paragraph{Benefici dell'Esecuzione Parallela}
L'abilità di eseguire più task contemporaneamente porta a una riduzione significativa del tempo di esecuzione per i problemi che possono essere suddivisi in parti indipendenti, ottimizzando l'uso delle risorse di elaborazione disponibili.

\subsection{Pipelining}
Il pipelining è un'efficace strategia di esecuzione parallela in cui un task è diviso in diverse fasi. Ogni fase è elaborata da una diversa unità di processamento, permettendo un flusso continuo di esecuzione simile a quello di una catena di montaggio industriale.

\paragraph{Efficienza del Pipelining}
Attraverso il pipelining, diverse fasi di un processo possono essere eseguite simultaneamente, migliorando l'efficienza e la velocità complessive del sistema di elaborazione.

\section{Memoria nei Sistemi Paralleli}

\subsection{Memoria Condivisa}
In architetture con memoria condivisa, tutti i processori accedono a una memoria fisica comune, consentendo una comunicazione e sincronizzazione efficienti tra i task. Tuttavia, questo modello può comportare dei collo di bottiglia dovuti alla competizione per l'accesso alla memoria.

\subsection{Memoria Distribuita}
Nei sistemi con memoria distribuita, ciascun processore accede a una propria memoria locale. Questo approccio migliora la scalabilità del sistema ma richiede meccanismi di comunicazione complessi per coordinare i task distribuiti su diversi processori.

\section{Comunicazione e Sincronizzazione}

\subsection{Comunicazione}
La comunicazione tra i task è fondamentale in un ambiente di calcolo parallelo. I meccanismi di comunicazione variano a seconda dell'architettura e possono includere l'uso di bus di memoria condivisa o reti di comunicazione.

\subsection{Sincronizzazione}
Per mantenere la coerenza e l'ordine nell'esecuzione parallela, i task devono sincronizzarsi periodicamente. Ciò è spesso realizzato attraverso punti di sincronizzazione nel programma, dove ogni task deve attendere gli altri prima di procedere.

\section{Prestazioni e Scalabilità}

\subsection{Granularità}
La granularità nel calcolo parallelo descrive il livello di suddivisione del lavoro computazionale e ha un impatto diretto sull'equilibrio tra calcolo e comunicazione. La granularità fine potrebbe richiedere una comunicazione più frequente, mentre quella grossolana meno frequente.

\subsection{Speedup e Overhead Parallelo}
Lo speedup misura l'efficacia dell'esecuzione parallela rispetto a quella seriale. L'overhead parallelo, che include il tempo di avvio dei task, le sincronizzazioni e le comunicazioni, può influenzare negativamente questo indicatore di prestazione.

\[
    \textit{Speedup} = \frac{\textit{Tempo di esecuzione seriale}}{\textit{Tempo di esecuzione parallelo}}
\]

\section{Architetture e Computazione Parallela}

\subsection{Processori Multi-core}
I processori multi-core contengono più core di elaborazione in un unico chip, permettendo l'esecuzione parallela di task su un singolo dispositivo fisico.

\subsection{Cluster Computing}
Il cluster computing utilizza un insieme di unità di calcolo, spesso commerciali, configurate per lavorare insieme come un unico sistema parallelo.

\subsection{Supercomputing}
Il supercomputing si basa sull'uso di computer ad alte prestazioni per affrontare problemi computazionali di grande scala, dove la velocità e la capacità di elaborazione sono essenziali.

\subsection{Edge Computing}
L'edge computing mira a portare la potenza di calcolo e la memorizzazione dei dati più vicino al punto di necessità, riducendo i tempi di risposta e il consumo di banda.

\section{Memoria Condivisa}

I computer paralleli a memoria condivisa presentano diverse caratteristiche,
ma in generale condividono la capacità per tutti i processori di accedere a
tutta la memoria come uno spazio di indirizzamento globale.

\begin{itemize}
    \item I processori multipli possono operare in modo indipendente, ma condividono
    le stesse risorse di memoria.
    \item Le modifiche in una posizione di memoria effettuate da un processore sono
    visibili a tutti gli altri processori.
    \item Le macchine a memoria condivisa possono essere suddivise in due classi
    principali in base ai tempi di accesso alla memoria: \texttt{UMA}
    (\textit{Uniform Memory Access})
    e \texttt{NUMA} (\textit{Non-Uniform Memory Access}).
\end{itemize}

\subsection{\texttt{UMA} (\textit{Uniform Memory Access})}
Le architetture \texttt{UMA} sono comunemente rappresentate oggi dalle
macchine Symmetric Multiprocessor (\texttt{SMP}), caratterizzate da processori
identici e accesso uniforme alla memoria con tempi di accesso uguali. Questo
modello è noto anche come \texttt{CC-UMA} (\textit{Cache Coherent \texttt{UMA}}),
dove la coerenza della
cache indica che se un processore aggiorna una posizione nella memoria condivisa,
tutti gli altri processori vengono informati dell'aggiornamento. La coerenza della
cache è ottenuta a livello hardware.

\paragraph{Vantaggi e Svantaggi}
\begin{itemize}
    \item \textbf{Vantaggi:} Lo spazio di indirizzamento globale offre una prospettiva
    di programmazione user-friendly per la memoria. La condivisione dei dati tra i
    task è sia rapida che uniforme grazie alla prossimità della memoria ai \texttt{CPU}.
    \item \textbf{Svantaggi:} Il principale svantaggio è la mancanza di scalabilità
    tra memoria e \texttt{CPU}. Aggiungere più \texttt{CPU} può aumentare
    geometricamente il traffico sul percorso memoria-\texttt{CPU} condiviso e, per i
    sistemi con coerenza della cache, aumentare geometricamente il traffico
    associato alla gestione della cache/memoria. È responsabilità del programmatore
    utilizzare costrutti di sincronizzazione che assicurino un accesso ``corretto''
    alla memoria globale. Inoltre, diventa sempre più difficile e costoso progettare
    e produrre macchine a memoria condivisa con un numero crescente di processori.
\end{itemize}

\subsection{\texttt{NUMA} (\textit{Non-Uniform Memory Access})}
Le architetture \texttt{NUMA} sono spesso realizzate collegando fisicamente due
o più \texttt{SMP}. Un \texttt{SMP} può accedere direttamente alla memoria di un altro \texttt{SMP},
ma non tutti i processori hanno tempi di accesso uguali a tutte le memorie.
L'accesso alla memoria attraverso il collegamento è più lento. Se la coerenza
della cache è mantenuta, queste architetture possono anche essere chiamate
\texttt{CC-NUMA}
(\textit{Cache Coherent \texttt{NUMA}}).

\paragraph{Vantaggi e Svantaggi}
\begin{itemize}
    \item \textbf{Vantaggi:} Similmente a \texttt{UMA}, \texttt{NUMA} offre
    uno spazio di indirizzamento globale che facilita la programmazione e la
    condivisione dei dati tra i task. La struttura di \texttt{NUMA} permette
    una migliore scalabilità rispetto a \texttt{UMA} quando si aggiungono
    processori, grazie alla distribuzione della memoria tra i vari \texttt{SMP}.
    \item \textbf{Svantaggi:} L'accesso non uniforme alla memoria può portare
    a prestazioni inconsistenti, specialmente in carichi di lavoro che richiedono
    un accesso frequente alla memoria attraverso i collegamenti \texttt{SMP}. La gestione
    della coerenza della cache, sebbene fornisca una visione coerente della memoria,
    può introdurre overhead significativo, specialmente in sistemi di grande
    dimensione.
\end{itemize}

\section{Memoria Distribuita}
Come i sistemi a memoria condivisa, anche quelli a memoria distribuita
variano notevolmente ma condividono una caratteristica comune: richiedono
una rete di comunicazione per connettere la memoria tra i vari processori.
In questi sistemi, ogni processore dispone di una propria memoria locale e
gli indirizzi di memoria in un processore non sono mappati su un altro processore,
eliminando così il concetto di spazio di indirizzamento globale.

\subsection{Funzionamento Indipendente e Coerenza della Cache}
Poiché ogni processore ha la propria memoria locale, opera indipendentemente.
Le modifiche che effettua nella sua memoria locale non influenzano la memoria
degli altri processori, rendendo inapplicabile il concetto di coerenza della cache.
Quando un processore necessita di accedere ai dati in un altro processore, spesso
è compito del programmatore definire esplicitamente come e quando i dati vengono
comunicati. Anche la sincronizzazione tra i task è responsabilità del programmatore.

\subsection{Tessuto di Rete}
Il ``tessuto'' di rete utilizzato per il trasferimento dei dati varia ampiamente,
sebbene possa essere semplice come Ethernet.
\subsubsection{Vantaggi e svantaggi}
\begin{itemize}
    \item \textbf{Vantaggi} 
    \begin{itemize}
        \item La memoria è scalabile con il numero di processori. Aumentando
        il numero di processori, la dimensione della memoria aumenta proporzionalmente.
        \item Ogni processore può accedere rapidamente alla propria memoria senza
        interferenze e senza l'overhead necessario per mantenere la coerenza della
        cache.
        \item Costo-efficacia: è possibile utilizzare processori e reti commerciali.
    \end{itemize}
    \item \textbf{Svantaggi}
    \begin{itemize}
        \item Il programmatore è responsabile di molti dettagli associati alla
        comunicazione dei dati tra i processori.
        \item Può essere difficile mappare le strutture dati esistenti, basate
        sulla memoria globale, a questa organizzazione della memoria.
        \item Tempi di accesso alla memoria non uniformi (\texttt{NUMA}).
    \end{itemize}
\end{itemize}
\section{Memorie ibride, distribuite e condivise}

I supercomputer più grandi e veloci al mondo oggi impiegano architetture ibride che combinano elementi di memoria condivisa e memoria distribuita.

\subsection{Componente di Memoria Condivisa}
La componente di memoria condivisa è solitamente costituita da una macchina
\texttt{SMP} (\textit{Symmetric Multiprocessing}) con coerenza della cache.
I processori all'interno di un dato \texttt{SMP} possono indirizzare la memoria della
macchina come se fosse globale, permettendo un accesso rapido e efficiente ai
dati condivisi.

\subsection{Componente di Memoria Distribuita}
La componente di memoria distribuita si realizza tramite il collegamento
in rete di più macchine \texttt{SMP}. Ogni \texttt{SMP} è a conoscenza soltanto della propria
memoria e non di quella presente su un altro \texttt{SMP}. Di conseguenza, sono necessarie
comunicazioni di rete per spostare i dati da un \texttt{SMP} all'altro.

\paragraph{Tendenze Attuali}
Le tendenze attuali sembrano indicare che questo tipo di architettura di
memoria continuerà a prevalere e ad espandersi nell'alta fascia del calcolo
per il futuro prevedibile. L'approccio ibrido offre il meglio di entrambi i
mondi: l'efficienza e la facilità di programmazione della memoria condivisa
e la scalabilità e flessibilità della memoria distribuita.

\subsubsection{Vantaggi e svantaggi}
\begin{itemize}
    \item \textbf{Vantaggi} 
    \begin{itemize}
        \item \textbf{Scalabilità:} L'architettura ibrida permette ai supercomputer
        di scalare efficacemente aggiungendo più \texttt{SMP}, aumentando la potenza di
        calcolo e la memoria disponibile.
        \item \textbf{Flessibilità:} Gli sviluppatori possono ottimizzare
        le prestazioni sfruttando la memoria locale nei nodi \texttt{SMP} per l'accesso
        ad alta velocità e utilizzare la memoria distribuita per il lavoro
        collaborativo tra \texttt{SMP}.
        \item \textbf{Efficienza:} La combinazione di memoria condivisa e
        distribuita può migliorare l'efficienza complessiva del sistema,
        bilanciando carico di lavoro e comunicazioni di rete.
    \end{itemize}
    \item \textbf{Svantaggi}
    \begin{itemize}
        \item \textbf{Complessità:} La programmazione e la gestione di architetture
        ibride sono più complesse a causa della necessità di bilanciare l'uso
        di memoria condivisa e distribuita.
        \item \textbf{Costo:} La costruzione e manutenzione di supercomputer con
        architetture ibride possono essere costose, data la complessità del
        hardware e del software.
        \item \textbf{Coerenza dei Dati:} Mantenere la coerenza dei dati tra
        la memoria condivisa e quella distribuita può richiedere meccanismi di
        sincronizzazione avanzati, aggiungendo un ulteriore livello di complessità.
    \end{itemize}
\end{itemize}