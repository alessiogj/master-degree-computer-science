\chapter{\texttt{MPI} - \textit{Message Passing Interface}}
\section{\texttt{MPI}}
\texttt{MPI} (\textit{Message Passing Interface}) è una libreria di comunicazione
per la programmazione parallela su sistemi distribuiti. \texttt{MPI} fornisce
Si utilizza quando non è presente una memoria condivisa tra i processi, 
in modo che i processi possano comunicare tra loro tramite messaggi.

\subsection{Introduzione}
\texttt{MPI} è una libreria di comunicazione per la programmazione parallela
su sistemi distribuiti. \texttt{MPI} fornisce un'interfaccia standard per la
comunicazione tra processi, consentendo a programmi paralleli di scambiare
messaggi e sincronizzarsi in modo efficiente.

La primitiva più semplice di comunicazione in \texttt{MPI} è la \texttt{MPI\_Send}
e la \texttt{MPI\_Recv}, che consentono a due processi di scambiare messaggi
in modo sincrono. Queste primitive possono essere utilizzate per implementare
algoritmi di comunicazione più complessi, come la raccolta di dati, la distribuzione
di lavoro e la sincronizzazione tra processi.

Gli obiettivi di \texttt{MPI} includono:
\begin{itemize}
  \item \textbf{Portabilità:} \texttt{MPI} è progettato per funzionare su una
  vasta gamma di architetture di calcolo parallelo, inclusi cluster, supercomputer
  e sistemi di calcolo distribuito.
  \item \textbf{Scalabilità:} \texttt{MPI} è progettato per supportare applicazioni
  parallele di grandi dimensioni con migliaia o milioni di processi, consentendo
  una crescita flessibile delle risorse di calcolo.
  \item \textbf{Portabilità software:} \texttt{MPI} fornisce un'interfaccia standard
  per la comunicazione tra processi, consentendo ai programmatori di scrivere
  codice parallelo che può essere eseguito su diverse piattaforme senza modifiche.
  L'interfaccia è stata definita per \texttt{C/C++}, \texttt{Fortran}, \texttt{Python}
  e altri linguaggi di programmazione.
  \item \textbf{Portabilità hardware:} \texttt{MPI} è progettato per funzionare su
  una vasta gamma di hardware.
\end{itemize}
\subsubsection{Struttura di un programma \texttt{MPI}}
\begin{lstlisting}
  #include "mpi.h"

  // Inizializzazione dell'ambiente MPI

  // Corpo del programma, il programma che viene 
  // manualmente parallelizzato

  // Terminazione dell'ambiente MPI
\end{lstlisting}
Per garantire la portabilità i tipi di dati in \texttt{MPI} sono definiti
come \texttt{MPI\_Datatype}.

\subsection{Comunicazione e rango}
\texttt{MPI} utilizza oggetti chiamati \textit{communicators} per gestire la
comunicazione tra processi. Un communicator è un gruppo di processi che possono
scambiare messaggi tra loro. Ogni processo in un communicator è identificato
da un numero intero univoco chiamato \textit{rank}.

Se non viene specificato un communicator, \texttt{MPI} utilizza il communicator
predefinito \texttt{MPI::COMM\_WORLD}, che include tutti i processi in esecuzione.

I \textit{rank} vengono assegnati in modo sequenziale, partendo da 0 per il
primo processo, 1 per il secondo e così via. 

\subsection{Funzioni chiave di \texttt{MPI}}

\subsubsection{Inizializzazione e terminazione}
\begin{lstlisting}
  MPI::Init(&argc, &argv);
\end{lstlisting}

\subsubsection{Rank e dimensione del communicator}
\begin{lstlisting}
  int MPI::COMM::Get_rank();
  int MPI::COMM::Get_size();
\end{lstlisting}

\subsubsection{Nome del processore}
\begin{lstlisting}
  MPI::Get_processor_name(char* name, int& len);
\end{lstlisting}

\subsubsection{Terminazione dell'ambiente \texttt{MPI}}
\begin{lstlisting}
  MPI::Finalize();
\end{lstlisting}

\begin{lstlisting}
  MPI::COMM::Abort(int errorcode);
\end{lstlisting}

\subsubsection{Comunicazione}
\begin{lstlisting}
  bool MPI::Is_initialized();
\end{lstlisting}

\subsubsection{Minutaggio e temporizzazione}
\begin{lstlisting}
  double MPI::Wtime();
\end{lstlisting}

\begin{lstlisting}
  double MPI::Wtick();
\end{lstlisting}

\subsection{Hello World in \texttt{MPI}}
\begin{lstlisting}
  #include <mpi.h>
  #include <iostream>

  int main(int argc, char** argv) {
    // Inizializzazione dell'ambiente MPI
    MPI::Init(argc, argv);
    // Ottenere il numero di processi e il rank del processo
    int world_size = MPI::COMM_WORLD.Get_size();
    int world_rank = MPI::COMM_WORLD.Get_rank();
    // Ottenere il nome del processore
    char processor_name[MPI_MAX_PROCESSOR_NAME];
    int name_len;
    MPI::Get_processor_name(processor_name, name_len);
    // Stampa del messaggio di saluto
    std::cout << "Hello from processor " << processor_name << ", rank " << world_rank << " out of " << world_size << " processors" << std::endl;
    // Terminazione dell'ambiente MPI
    MPI::Finalize();
    return 0;
  }
\end{lstlisting}

\subsection{Applicazioni e buffer di comunicazione}
Un \textit{system buffer} è un'area di memoria utilizzata
per memorizzare i dati trasmessi tra i processi. Questo
buffer può essere utilizzato per inviare e ricevere messaggi
tra i processi, consentendo la comunicazione e la sincronizzazione
tra i processi.

Lo spazio di indirizzamento è gestito dall'utente.

Una \texttt{SEND} bloccante ritorna il risultato solo dopo che la 
modifica dell'application buffer è stata completata in modo 
corretto.
Ciò significa che il processo mittente si sblocca quando il processo 
destinatario ha completato la ricezione del messaggio.
Quando il processo invoca una \texttt{RECIVE} bloccante, il processo
si blocca fino a quando il messaggio non è stato ricevuto correttamente.
Se la chiamata di ricezione viene eseguita prima che il messaggio sia
stato inviato, il processo si blocca fino a quando il messaggio non è
stato inviato.

Quando un processo invia una sequenza di messaggi, il processo
destinatario riceve i messaggi nello stesso ordine in cui sono stati
inviati.

\texttt{MPI} non garantisce il principio di equità, il che significa
che non garantisce che i messaggi vengano ricevuti nell'ordine in cui
sono stati inviati.

\subsection{Comunicazione bloccante}
\begin{lstlisting}
  MPI::COMM::Send(void* buf, int count, MPI::Datatype datatype& datatype, int dest, int tag);
\end{lstlisting}

\begin{lstlisting}
  MPI::COMM::Recv(void* buf, int count, MPI::Datatype datatype& datatype, int source, int tag, MPI::Status& status);
\end{lstlisting}

\begin{lstlisting}
  MPI::COMM::Sendrecv(void* sendbuf, int sendcount, 
            MPI::Datatype sendtype, int dest, int sendtag,v
            oid* recvbuf, int recvcount, MPI::Datatype recvtype,
            int source, int recvtag, MPI::Status& status);
\end{lstlisting}

\begin{lstlisting}
  MPI::COMM::Ssend(void* buf, int count, MPI::Datatype datatype, int dest, int tag);
\end{lstlisting}

\begin{lstlisting}
  MPI::COMM::Rsend(void* buf, int count, MPI::Datatype datatype, int dest, int tag);
\end{lstlisting}

\subsection{Comunicazione non bloccante}

\begin{lstlisting}
  MPI::COMM::Isend(void* buf, int count, MPI::Datatype datatype, int dest, int tag);
\end{lstlisting}

\begin{lstlisting}
  MPI::COMM::Irecv(void* buf, int count, MPI::Datatype datatype, int source, int tag);
\end{lstlisting}

\begin{lstlisting}
  MPI::COMM::Irsend(void* buf, int count, MPI::Datatype datatype, int dest, int tag);
\end{lstlisting}

\begin{lstlisting}
  MPI::COMM::Issend(void* buf, int count, MPI::Datatype datatype, int dest, int tag);
\end{lstlisting}

